{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import SamModel, SamProcessor\n",
    "from diffusers import DiffusionPipeline, AutoPipelineForText2Image, AutoPipelineForInpainting\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM\n",
    "\n",
    "Complete the following cell by loading the pretrained SAM from Facebook/Meta. Remember to:\n",
    "\n",
    "1. Move the model to the GPU by adding `.to(\"cuda\")`\n",
    "2. Add the option `torch_dtype=torch.float16` to your call of AutoPipelineForInpainting.from_pretrained\n",
    "\n",
    "This cell might take a couple of minutes to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SAM model as we have seen in the class\n",
    "# Remeber to load it on the GPU by adding .to(\"cuda\")\n",
    "# at the end\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "check_point = \"facebook/sam-vit-base\"\n",
    "model = SamModel.from_pretrained(check_point).to(device)# your code here\n",
    "\n",
    "# Load the SamProcessor using the facebook/sam-vit-base\n",
    "# checkpoint\n",
    "processor = SamProcessor.from_pretrained(check_point)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the mask\n",
    "\n",
    "Now that you have loaded SAM, complete the following function that uses SAM to produce a segmentation mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_rgb(mask):\n",
    "    \"\"\"\n",
    "    Transforms a binary mask into an RGBA image for visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    bg_transparent = np.zeros(mask.shape + (4, ), dtype=np.uint8)\n",
    "    \n",
    "    # Color the area we will replace in green\n",
    "    # (this vector is [Red, Green, Blue, Alpha])\n",
    "    bg_transparent[mask == 1] = [0, 255, 0, 127]\n",
    "    \n",
    "    return bg_transparent\n",
    "\n",
    "\n",
    "def get_processed_inputs(image, input_points):\n",
    "    \n",
    "    # Use the processor to generate the right inputs\n",
    "    # for SAM\n",
    "    # Use \"image\" as your image\n",
    "    # Use 'input_points' as your input_points,\n",
    "    # and remember to use the option return_tensors='pt'\n",
    "    # Also, remember to add .to(\"cuda\") at the end\n",
    "    inputs = processor(image, input_points=input_points, return_tensors=\"pt\").to(device)# your code here\n",
    "    \n",
    "    # Call SAM\n",
    "    outputs = model(**inputs)# your code here)\n",
    "    \n",
    "    # Now let's post process the outputs of SAM to obtain the masks\n",
    "    masks = processor.image_processor.post_process_masks(\n",
    "       outputs.pred_masks.cpu(), \n",
    "       inputs[\"original_sizes\"].cpu(), \n",
    "       inputs[\"reshaped_input_sizes\"].cpu()\n",
    "    )\n",
    "    \n",
    "    # Here we select the mask with the highest score\n",
    "    # as the mask we will use. You can experiment with also\n",
    "    # other selection criteria, for example the largest mask\n",
    "    # instead of the most confident mask\n",
    "    best_mask = masks[0][0][outputs.iou_scores.argmax()] \n",
    "\n",
    "    # NOTE: we invert the mask by using the ~ operator because\n",
    "    # so that the subject pixels will have a value of 0 and the\n",
    "    # background pixels a value of 1. This will make it more convenient\n",
    "    # to infill the background\n",
    "    return ~best_mask.cpu().numpy()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test what we have done so far. By executing this cell you should get a visualization of the mask for the following car:\n",
    "\n",
    "<img src='car.png' width=\"200px\"></img>\n",
    "\n",
    "Let's see what happens in this cell:\n",
    "1. We open the image of the car and **we resize it to 512 by 512 pixels** (a square image). This makes things simpler for this project\n",
    "2. We define a few points on the image that indicate where the car is\n",
    "3. We use the function we have defined to generate a mask using SAM\n",
    "4. We visualize the mask\n",
    "\n",
    "The mask should look like this:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "If it doesn't or you get errors, double check the code you have completed above and fix it before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGBA size=128x128>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_image = Image.open(\"car.png\").convert(\"RGB\").resize((512, 512))\n",
    "\n",
    "# These are the coordinates of two points on the car\n",
    "input_points = [[[150, 170], [300, 250]]]\n",
    "\n",
    "mask = get_processed_inputs(raw_image, input_points)\n",
    "\n",
    "Image.fromarray(mask_to_rgb(mask)).resize((128, 128))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inpainting\n",
    "\n",
    "Now that we have completed the SAM setup, let's move to the inpainting setup.\n",
    "\n",
    "Let's start by loading our inpainting pipeline. We will use the `diffusers/stable-diffusion-xl-1.0-inpainting-0.1` pretrained model and the `AutoPipelineForInpainting` as we have seen in our `diffusers` demo in Lesson 5.\n",
    "\n",
    "Complete the following code and run it (it might take a few minutes to run):\n",
    "\n",
    "> **NOTE**: you will probably see a warning similar to ``The config attributes {'decay'...``. Please ignore it. It is a warning generated by the diffusers library that does not constitute a problem for our application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]Error while downloading from https://cdn-lfs.huggingface.co/repos/ec/4b/ec4bd842cf56b57db8113ab13465f3330553092c0e83300bfe05baa0d84ee92f/df858870144f8af28e1d23aaf92a5238bfb5e3809775eca4e04b80516412c327?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&Expires=1716450691&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQ1MDY5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80Yi9lYzRiZDg0MmNmNTZiNTdkYjgxMTNhYjEzNDY1ZjMzMzA1NTMwOTJjMGU4MzMwMGJmZTA1YmFhMGQ4NGVlOTJmL2RmODU4ODcwMTQ0ZjhhZjI4ZTFkMjNhYWY5MmE1MjM4YmZiNWUzODA5Nzc1ZWNhNGUwNGI4MDUxNjQxMmMzMjc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=v3AU0gfljWST2RuWpd4yznbHR6QDsOy5-WEFT8BUR7ZXYHUI2OjQEbPptlsEKPLcO0Ott21lAgxWpcisZN39%7E7PTWSMFJI5z9SjnituM%7EV4M2NmYvB9I7cBNl-hd2Spfjt4O-7o8fBtb37D7McRxBZgI-hmC4dRAItWrtbCrh015qAl5Ehsff%7ENOxyjeHlmVjUx3NnDO0LdcHijrG2xmyWDnElRQzUqyWd0kwHYFeRIs94I-HgRKZBz9iISMe8CfF1IHuqgGVBLC8jeMfkDG-LjPnp6nOjJ7ViBHQpkjIvn-mN7nQKoI0C-KWun5x2HeL2xF9qASWSMMb88UfPEGTg__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/ec/4b/ec4bd842cf56b57db8113ab13465f3330553092c0e83300bfe05baa0d84ee92f/98a14dc6fe8d71c83576f135a87c61a16561c9c080abba418d2cc976ee034f88?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&Expires=1716450691&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQ1MDY5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80Yi9lYzRiZDg0MmNmNTZiNTdkYjgxMTNhYjEzNDY1ZjMzMzA1NTMwOTJjMGU4MzMwMGJmZTA1YmFhMGQ4NGVlOTJmLzk4YTE0ZGM2ZmU4ZDcxYzgzNTc2ZjEzNWE4N2M2MWExNjU2MWM5YzA4MGFiYmE0MThkMmNjOTc2ZWUwMzRmODg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=nvGk4zeV5w2hV1Hj%7E%7E1uo3raJqx7I-DBHX%7E3O6klDlPf-qGLT23u10u13Ig2wg0Us3B0PLOSMgf4XB6i7nWq-ogw9yohNHMypRyh1SlRke6sAwPJR156KRnW1Cxh%7Eyi9BrqoQsjsS3vvnqo3tmiAcRDIXImMSLogTSA1C5DNwJPMiR9eMwUvPpoxe%7Els5ODFCeJLQ-W%7E4VfAa0O7C5vdWoMKgwKppssXiz1p8npfOfeianOoI63ndLSDK-aXrsIfHThm21P-W2IOwb91zaku5ngUC5xithAE5TB4Dx%7EyeOmwJmNsngtPV1vPNgaxUh%7Ew7LKQpwMGFrPK-0kDarW9Ig__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/ec/4b/ec4bd842cf56b57db8113ab13465f3330553092c0e83300bfe05baa0d84ee92f/df858870144f8af28e1d23aaf92a5238bfb5e3809775eca4e04b80516412c327?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&Expires=1716450691&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQ1MDY5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80Yi9lYzRiZDg0MmNmNTZiNTdkYjgxMTNhYjEzNDY1ZjMzMzA1NTMwOTJjMGU4MzMwMGJmZTA1YmFhMGQ4NGVlOTJmL2RmODU4ODcwMTQ0ZjhhZjI4ZTFkMjNhYWY5MmE1MjM4YmZiNWUzODA5Nzc1ZWNhNGUwNGI4MDUxNjQxMmMzMjc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=v3AU0gfljWST2RuWpd4yznbHR6QDsOy5-WEFT8BUR7ZXYHUI2OjQEbPptlsEKPLcO0Ott21lAgxWpcisZN39%7E7PTWSMFJI5z9SjnituM%7EV4M2NmYvB9I7cBNl-hd2Spfjt4O-7o8fBtb37D7McRxBZgI-hmC4dRAItWrtbCrh015qAl5Ehsff%7ENOxyjeHlmVjUx3NnDO0LdcHijrG2xmyWDnElRQzUqyWd0kwHYFeRIs94I-HgRKZBz9iISMe8CfF1IHuqgGVBLC8jeMfkDG-LjPnp6nOjJ7ViBHQpkjIvn-mN7nQKoI0C-KWun5x2HeL2xF9qASWSMMb88UfPEGTg__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/ec/4b/ec4bd842cf56b57db8113ab13465f3330553092c0e83300bfe05baa0d84ee92f/79f531155c765c22c89e23328793a2e91a1178070af961c57e2eae5f0509b65b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1716450691&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQ1MDY5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80Yi9lYzRiZDg0MmNmNTZiNTdkYjgxMTNhYjEzNDY1ZjMzMzA1NTMwOTJjMGU4MzMwMGJmZTA1YmFhMGQ4NGVlOTJmLzc5ZjUzMTE1NWM3NjVjMjJjODllMjMzMjg3OTNhMmU5MWExMTc4MDcwYWY5NjFjNTdlMmVhZTVmMDUwOWI2NWI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=c6KAeNjwRcbNl0UMFCQ%7E8AeO9r01UDMipk%7EU4fnXuSr0QtlF0iSAWT2mVcwJSV4Bz6aHkxcx-n5uIzKXCfYAPaZTSZV7Tmrgwh54nC%7Egq9ITYL-IChLuxwyNmPafUOYG28RroYjvHWNF0slg1v7FZurGjBzFt92fYEE22HLpA8ynwonp7lrQFh8X5OaxMGHRFIpK4-D12to6sUIBOaiXhdaPXaHz-ufkt0JqHAx-TM74sT7g-2aVHb5xLrCTnJAaubqqbnT%7E6KPzsegubGOxj2QcSDfmk6eWIuDe2dAzRFFNB9GJhQ8kNlX4V9J06A0N3gBXGAi1XebWMOZtyGcP3g__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Fetching 18 files:  22%|██▏       | 4/18 [04:34<16:02, 68.72s/it]Error while downloading from https://cdn-lfs.huggingface.co/repos/ec/4b/ec4bd842cf56b57db8113ab13465f3330553092c0e83300bfe05baa0d84ee92f/283bb90f987a133dec11947571aca17692ed32f3fff708441ac8eedcfa4a040e?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1716450691&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQ1MDY5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80Yi9lYzRiZDg0MmNmNTZiNTdkYjgxMTNhYjEzNDY1ZjMzMzA1NTMwOTJjMGU4MzMwMGJmZTA1YmFhMGQ4NGVlOTJmLzI4M2JiOTBmOTg3YTEzM2RlYzExOTQ3NTcxYWNhMTc2OTJlZDMyZjNmZmY3MDg0NDFhYzhlZWRjZmE0YTA0MGU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Ni5gfQXAft0L-ht5JpFTDtpwQb9rjwyoIqRR9Y0Uqj6i9JBWSLSaYRMN8yid4wm-7aIOvhRie1F44cO0Q9sRmABXCgbnYO6zNS929MuNKNOdCmsVE-30Wa2IrL-5LXcjYW%7EgVB1xxC0YmWplP7Vx%7EZJ7xPbbQeiuGGE%7Eh0Oh4c1AQqcguhhmm8kjp%7EJGczb7YABHmWHK7KLhDjiXOACl%7EMDvalfJd5HKoR-gY6CUJ4q3m4Rt6LInUggzckzU5LLH71JQyzl0ldM2xvBbnG2K%7EymmtDuHqjQ7MMfj2wt5edFI-FOujEpAX16OKiVLF7WrdriUI17FTyc1FQso7MRP6w__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/ec/4b/ec4bd842cf56b57db8113ab13465f3330553092c0e83300bfe05baa0d84ee92f/df858870144f8af28e1d23aaf92a5238bfb5e3809775eca4e04b80516412c327?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&Expires=1716450691&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQ1MDY5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80Yi9lYzRiZDg0MmNmNTZiNTdkYjgxMTNhYjEzNDY1ZjMzMzA1NTMwOTJjMGU4MzMwMGJmZTA1YmFhMGQ4NGVlOTJmL2RmODU4ODcwMTQ0ZjhhZjI4ZTFkMjNhYWY5MmE1MjM4YmZiNWUzODA5Nzc1ZWNhNGUwNGI4MDUxNjQxMmMzMjc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=v3AU0gfljWST2RuWpd4yznbHR6QDsOy5-WEFT8BUR7ZXYHUI2OjQEbPptlsEKPLcO0Ott21lAgxWpcisZN39%7E7PTWSMFJI5z9SjnituM%7EV4M2NmYvB9I7cBNl-hd2Spfjt4O-7o8fBtb37D7McRxBZgI-hmC4dRAItWrtbCrh015qAl5Ehsff%7ENOxyjeHlmVjUx3NnDO0LdcHijrG2xmyWDnElRQzUqyWd0kwHYFeRIs94I-HgRKZBz9iISMe8CfF1IHuqgGVBLC8jeMfkDG-LjPnp6nOjJ7ViBHQpkjIvn-mN7nQKoI0C-KWun5x2HeL2xF9qASWSMMb88UfPEGTg__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/ec/4b/ec4bd842cf56b57db8113ab13465f3330553092c0e83300bfe05baa0d84ee92f/df858870144f8af28e1d23aaf92a5238bfb5e3809775eca4e04b80516412c327?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&Expires=1716450691&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQ1MDY5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80Yi9lYzRiZDg0MmNmNTZiNTdkYjgxMTNhYjEzNDY1ZjMzMzA1NTMwOTJjMGU4MzMwMGJmZTA1YmFhMGQ4NGVlOTJmL2RmODU4ODcwMTQ0ZjhhZjI4ZTFkMjNhYWY5MmE1MjM4YmZiNWUzODA5Nzc1ZWNhNGUwNGI4MDUxNjQxMmMzMjc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=v3AU0gfljWST2RuWpd4yznbHR6QDsOy5-WEFT8BUR7ZXYHUI2OjQEbPptlsEKPLcO0Ott21lAgxWpcisZN39%7E7PTWSMFJI5z9SjnituM%7EV4M2NmYvB9I7cBNl-hd2Spfjt4O-7o8fBtb37D7McRxBZgI-hmC4dRAItWrtbCrh015qAl5Ehsff%7ENOxyjeHlmVjUx3NnDO0LdcHijrG2xmyWDnElRQzUqyWd0kwHYFeRIs94I-HgRKZBz9iISMe8CfF1IHuqgGVBLC8jeMfkDG-LjPnp6nOjJ7ViBHQpkjIvn-mN7nQKoI0C-KWun5x2HeL2xF9qASWSMMb88UfPEGTg__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/ec/4b/ec4bd842cf56b57db8113ab13465f3330553092c0e83300bfe05baa0d84ee92f/df858870144f8af28e1d23aaf92a5238bfb5e3809775eca4e04b80516412c327?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&Expires=1716450691&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNjQ1MDY5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy80Yi9lYzRiZDg0MmNmNTZiNTdkYjgxMTNhYjEzNDY1ZjMzMzA1NTMwOTJjMGU4MzMwMGJmZTA1YmFhMGQ4NGVlOTJmL2RmODU4ODcwMTQ0ZjhhZjI4ZTFkMjNhYWY5MmE1MjM4YmZiNWUzODA5Nzc1ZWNhNGUwNGI4MDUxNjQxMmMzMjc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=v3AU0gfljWST2RuWpd4yznbHR6QDsOy5-WEFT8BUR7ZXYHUI2OjQEbPptlsEKPLcO0Ott21lAgxWpcisZN39%7E7PTWSMFJI5z9SjnituM%7EV4M2NmYvB9I7cBNl-hd2Spfjt4O-7o8fBtb37D7McRxBZgI-hmC4dRAItWrtbCrh015qAl5Ehsff%7ENOxyjeHlmVjUx3NnDO0LdcHijrG2xmyWDnElRQzUqyWd0kwHYFeRIs94I-HgRKZBz9iISMe8CfF1IHuqgGVBLC8jeMfkDG-LjPnp6nOjJ7ViBHQpkjIvn-mN7nQKoI0C-KWun5x2HeL2xF9qASWSMMb88UfPEGTg__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Fetching 18 files: 100%|██████████| 18/18 [28:07<00:00, 93.77s/it] \n",
      "Loading pipeline components...:  57%|█████▋    | 4/7 [00:06<00:05,  1.85s/it]The config attributes {'decay': 0.9999, 'inv_gamma': 1.0, 'min_decay': 0.0, 'optimization_step': 37000, 'power': 0.6666666666666666, 'update_after_step': 0, 'use_ema_warmup': False} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:29<00:00,  4.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the AutoPipelineForInpainting pipeline \n",
    "# (remember the diffusers demo in lesson 5)\n",
    "# The checkpoint we want to use is \n",
    "# \"diffusers/stable-diffusion-xl-1.0-inpainting-0.1\"\n",
    "# Remember to add torch_dtype=torch.float16 as an option\n",
    "device = torch.device(\"mps\")\n",
    "pipeline = AutoPipelineForInpainting.from_pretrained(\"diffusers/stable-diffusion-xl-1.0-inpainting-0.1\", \n",
    "                                                     torch_dtype=torch.float16\n",
    "                                                     ).to(device)\n",
    "# your code here\n",
    "\n",
    "# This will make it more efficient on our hardware\n",
    "pipeline.enable_model_cpu_offload()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the following function that gets in input:\n",
    "1. The raw image\n",
    "2. The mask generated by SAM (a numpy array)\n",
    "3. The text prompt for the infill\n",
    "4. An optional negative prompt\n",
    "5. An optional seed for repeatibility\n",
    "6. The Classifier-Free Guidance Scale (CFGS). If you don't remember what this is, refer to the Text Conditioning explanation in Lesson 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint(raw_image, input_mask, prompt, negative_prompt=None, seed=74294536, cfgs=7):\n",
    "    \n",
    "    mask_image = Image.fromarray(input_mask)\n",
    "    \n",
    "    rand_gen = torch.manual_seed(seed)\n",
    "\n",
    "    # Use the pipeline we have created in the previous cell\n",
    "    # Use \"prompt\" as prompt, \n",
    "    # \"negative_prompt\" as the negative prompt,\n",
    "    # raw_image as the image,\n",
    "    # mask_image as the mask_image,\n",
    "    # rand_gen as the generator and\n",
    "    # cfgs as the guidance_scale\n",
    "    \n",
    "    image = pipeline(\n",
    "        prompt=prompt,\n",
    "        negative_image_embeds=negative_prompt, \n",
    "        image=raw_image,\n",
    "        mask_image=mask_image,\n",
    "        generator=rand_gen,\n",
    "        guidance_scale=cfgs\n",
    "      # your code here\n",
    "    ).images[0]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our inpainting on the mask we have obtained earlier with SAM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma car driving on Mars. Studio lights, 1970s\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m negative_prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39martifacts, low quality, distortion\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m image \u001b[39m=\u001b[39m inpaint(raw_image, mask, prompt, negative_prompt)\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36minpaint\u001b[0;34m(raw_image, input_mask, prompt, negative_prompt, seed, cfgs)\u001b[0m\n\u001b[1;32m      5\u001b[0m rand_gen \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Use the pipeline we have created in the previous cell\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Use \"prompt\" as prompt, \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# \"negative_prompt\" as the negative prompt,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# rand_gen as the generator and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# cfgs as the guidance_scale\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m image \u001b[39m=\u001b[39m pipeline(\n\u001b[1;32m     16\u001b[0m     prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     17\u001b[0m     negative_image_embeds\u001b[39m=\u001b[39;49mnegative_prompt, \n\u001b[1;32m     18\u001b[0m     image\u001b[39m=\u001b[39;49mraw_image,\n\u001b[1;32m     19\u001b[0m     mask_image\u001b[39m=\u001b[39;49mmask_image,\n\u001b[1;32m     20\u001b[0m     generator\u001b[39m=\u001b[39;49mrand_gen,\n\u001b[1;32m     21\u001b[0m     guidance_scale\u001b[39m=\u001b[39;49mcfgs\n\u001b[1;32m     22\u001b[0m   \u001b[39m# your code here\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m )\u001b[39m.\u001b[39mimages[\u001b[39m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py:1473\u001b[0m, in \u001b[0;36mStableDiffusionXLInpaintPipeline.__call__\u001b[0;34m(self, prompt, prompt_2, image, mask_image, masked_image_latents, height, width, padding_mask_crop, strength, num_inference_steps, timesteps, denoising_start, denoising_end, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, original_size, crops_coords_top_left, target_size, negative_original_size, negative_crops_coords_top_left, negative_target_size, aesthetic_score, negative_aesthetic_score, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[39m# 3. Encode input prompt\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m text_encoder_lora_scale \u001b[39m=\u001b[39m (\n\u001b[1;32m   1465\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attention_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcross_attention_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1466\u001b[0m )\n\u001b[1;32m   1468\u001b[0m (\n\u001b[1;32m   1469\u001b[0m     prompt_embeds,\n\u001b[1;32m   1470\u001b[0m     negative_prompt_embeds,\n\u001b[1;32m   1471\u001b[0m     pooled_prompt_embeds,\n\u001b[1;32m   1472\u001b[0m     negative_pooled_prompt_embeds,\n\u001b[0;32m-> 1473\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_prompt(\n\u001b[1;32m   1474\u001b[0m     prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m   1475\u001b[0m     prompt_2\u001b[39m=\u001b[39;49mprompt_2,\n\u001b[1;32m   1476\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m   1477\u001b[0m     num_images_per_prompt\u001b[39m=\u001b[39;49mnum_images_per_prompt,\n\u001b[1;32m   1478\u001b[0m     do_classifier_free_guidance\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_classifier_free_guidance,\n\u001b[1;32m   1479\u001b[0m     negative_prompt\u001b[39m=\u001b[39;49mnegative_prompt,\n\u001b[1;32m   1480\u001b[0m     negative_prompt_2\u001b[39m=\u001b[39;49mnegative_prompt_2,\n\u001b[1;32m   1481\u001b[0m     prompt_embeds\u001b[39m=\u001b[39;49mprompt_embeds,\n\u001b[1;32m   1482\u001b[0m     negative_prompt_embeds\u001b[39m=\u001b[39;49mnegative_prompt_embeds,\n\u001b[1;32m   1483\u001b[0m     pooled_prompt_embeds\u001b[39m=\u001b[39;49mpooled_prompt_embeds,\n\u001b[1;32m   1484\u001b[0m     negative_pooled_prompt_embeds\u001b[39m=\u001b[39;49mnegative_pooled_prompt_embeds,\n\u001b[1;32m   1485\u001b[0m     lora_scale\u001b[39m=\u001b[39;49mtext_encoder_lora_scale,\n\u001b[1;32m   1486\u001b[0m     clip_skip\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclip_skip,\n\u001b[1;32m   1487\u001b[0m )\n\u001b[1;32m   1489\u001b[0m \u001b[39m# 4. set timesteps\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdenoising_value_valid\u001b[39m(dnv):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_inpaint.py:632\u001b[0m, in \u001b[0;36mStableDiffusionXLInpaintPipeline.encode_prompt\u001b[0;34m(self, prompt, prompt_2, device, num_images_per_prompt, do_classifier_free_guidance, negative_prompt, negative_prompt_2, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, lora_scale, clip_skip)\u001b[0m\n\u001b[1;32m    626\u001b[0m     removed_text \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mbatch_decode(untruncated_ids[:, tokenizer\u001b[39m.\u001b[39mmodel_max_length \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m : \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    627\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    628\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe following part of your input was truncated because CLIP can only handle sequences up to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    629\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mtokenizer\u001b[39m.\u001b[39mmodel_max_length\u001b[39m}\u001b[39;00m\u001b[39m tokens: \u001b[39m\u001b[39m{\u001b[39;00mremoved_text\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    630\u001b[0m     )\n\u001b[0;32m--> 632\u001b[0m prompt_embeds \u001b[39m=\u001b[39m text_encoder(text_input_ids\u001b[39m.\u001b[39;49mto(device), output_hidden_states\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    634\u001b[0m \u001b[39m# We are only ALWAYS interested in the pooled output of the final text encoder\u001b[39;00m\n\u001b[1;32m    635\u001b[0m pooled_prompt_embeds \u001b[39m=\u001b[39m prompt_embeds[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m\"\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "prompt = \"a car driving on Mars. Studio lights, 1970s\"\n",
    "negative_prompt = \"artifacts, low quality, distortion\"\n",
    "\n",
    "image = inpaint(raw_image, mask, prompt, negative_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at what we have produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[39m=\u001b[39m make_image_grid([raw_image, Image\u001b[39m.\u001b[39mfromarray(mask_to_rgb(mask)), image\u001b[39m.\u001b[39mresize((\u001b[39m512\u001b[39m, \u001b[39m512\u001b[39m))], rows\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, cols\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m fig\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "fig = make_image_grid([raw_image, Image.fromarray(mask_to_rgb(mask)), image.resize((512, 512))], rows=1, cols=3)\n",
    "fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive app\n",
    "\n",
    "To make things a bit more fun, we have prepared an interactive app for you that uses the code you have completed and allow you to upload an image, run SAM, and generate the new background through a text prompt.\n",
    "\n",
    "Simply execute the following cell. The output will contain a preview of the app: **DO NOT USE IT**. Instead, you will also see a link similar to this:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Click on the second link (the public URL), from there you will be able to use the app much more comfortably.\n",
    "\n",
    "> NOTE: if for any reason you need to stop the app, click on the stop icon of the jupyter interface: ![image-3.png](attachment:image-3.png)  then **execute the next cell containing the code `my_app.close`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_app = app.generate_app(get_processed_inputs, inpaint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_app.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
